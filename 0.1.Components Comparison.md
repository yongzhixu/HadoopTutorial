[TOC] 



## [Apache Kudu, Impala, Hive, Spark SQL and Presto](https://www.quora.com/What-are-differences-between-Apache-Kudu-Apache-Impala-Apache-Hive-Apache-Spark-SQL-and-Presto-Are-all-of-them-SQL-engine-for-Hadoop)

There are many ***distributed SQL query engines***. Their technical solutions vary more or less.

- **Apache Hive** 

Apache Hive was one of the first SQL-like query interfaces developed over distributed data on top of Hadoop. Hive converts queries to Hadoop MapReduce jobs.

- **Apache Spark** 

Apache Spark is a cluster computing technology. It is not strictly dependent on Hadoop because it has its own cluster management. However, Spark is usually implemented on top of Hadoop that is taking care of distributed data storage. Spark SQL is a Spark component on top of Spark core that provides a way of querying and persisting structured and semi-structured data.

- **Apache Kudu** 

Apache Kudu is not really a SQL interface for Hadoop but a very well optimized **columnar database** designed to fit in with the Hadoop ecosystem. It has been integrated to work with Impala, MapReduce and Spark, and additional framework integrations are expected. The idea is that it can provide very fast scan performance.

- **Apache Impala** 

Apache Impala uses its own parallel processing architecture on top of HDFS instead of MapReduce jobs. ***Kudu and Impala are best used together***.

- **Presto**

Presto is a distributed SQL query engine and in many senses quite similar to others. However, ***Presto engine does not use MapReduce and it is very well optimized for fast performance.***



So, these tools are not exactly the same but they share a lot. Impala and Presto seem to be best for BI-type queries and Spark leads performance wise in large-scale analytics according to this report ([Big data face-off: Spark vs. Impala vs. Hive vs. Presto](http://www.infoworld.com/article/3131058/analytics/big-data-face-off-spark-vs-impala-vs-hive-vs-presto.html))



## Kudu vs HBase

https://www.g2.com/compare/apache-kudu-vs-hbase



## [HIVE vs Impala?](https://www.quora.com/What-is-the-difference-between-Apache-HIVE-and-Impala)

A2A: This post could be quite lengthy but I will be as concise as possible.

- In my view: Apache Hive and Apache Impala (incubating) are complementary SQL frameworks in the Apache Hadoop ecosystem; they apply to different use cases for different users.Hive [1], which transforms SQL queries into MapReduce or Apache Spark jobs under the covers, is great for long-running ETL jobs (for which fault tolerance is highly desirable; for such jobs, you don't want to have to re-do a long-running query that failed after several hours). For that reason, Hive is very popular with data engineers.

- Impala [2], which is basically an MPP analytic database on top of Hadoop and is largely written in C++ for speed, pushes data processing down to local DataNodes, avoiding network bottlenecks. Thanks to these architectural advantages, Impala enables low-latency/interactive queries, especially under multi-user load. This makes Impala very popular with data analysts who need and expect an interactive "BI" experience, even on Hadoop. (It's worth mentioning that because Impala uses the Hive Metastore and other Hive infrastructure, people who come from a Hive background will have little setup overhead.)

Both Hive and Impala can be run as YARN applications and are fully integrated with the Hadoop ecosystem.

[1] http://hive.apache.org

[2] http://impala.io

